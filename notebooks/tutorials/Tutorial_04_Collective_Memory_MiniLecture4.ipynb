{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba57328d",
   "metadata": {},
   "source": [
    "# Tutorial 4: Collective Digital Memory\n",
    "\n",
    "**WRIT 20833 - Mini-Lecture 4 Python Practice**\n",
    "\n",
    "> üì∫ **Connection to Previous Lesson:** This tutorial builds on [Mini-Lecture 4: Collective Digital Memory](../lecture-series/mini-lecture4/index.html) - exploring how code remembers what communities used to forget.\n",
    "\n",
    "> üîó **Building on Previous Skills:** This tutorial assumes you've completed Tutorials 1-3 and are comfortable with variables, string methods, conditionals, and basic individual data processing.\n",
    "\n",
    "---\n",
    "\n",
    "## Assumptions/Prerequisites\n",
    "\n",
    "This tutorial is designed for **Week 4** students and introduces **lists and loops** - the tools for processing populations rather than individuals.\n",
    "\n",
    "### Required Python Knowledge:\n",
    "**From Melanie Walsh Chapters 4-8:**\n",
    "- **Variables** (Chapter 4): Assignment, naming, re-assignment\n",
    "- **Data Types** (Chapter 5): Strings, integers, floats, booleans; f-strings\n",
    "- **String Methods** (Chapter 6): `.lower()`, `.upper()`, `.replace()`, `in` operator\n",
    "- **Comparisons & Conditionals** (Chapter 8): `==`, `!=`, `>`, `<`; `if`/`elif`/`else` statements\n",
    "\n",
    "### NEW in This Tutorial:\n",
    "**From Melanie Walsh Chapters 9-10 (Lists & Loops):**\n",
    "- **Lists** (Chapter 9): Creating lists, indexing, list methods like `.append()`\n",
    "- **For Loops** (Chapter 9): Iterating through lists with `for item in list:`\n",
    "- **List Processing** (Chapter 10): Building lists with loops, `enumerate()`, `Counter()`\n",
    "\n",
    "### What This Tutorial Adds:\n",
    "- **Collective processing**: Moving from individual cases to population analysis\n",
    "- **Digital memory systems**: How code preserves and categorizes at scale\n",
    "- **Historical continuity**: Connecting 1840s institutional records to modern data processing\n",
    "- **Critical analysis**: Understanding the politics of systematic categorization\n",
    "\n",
    "### Required Experience:\n",
    "- **Completed:** Tutorials 1-3 (Boundaries, Classification Logic, AI Agency)\n",
    "- **Comfortable with:** Individual data analysis and conditional logic\n",
    "- **NEW:** Ready to learn lists and loops for population-scale processing\n",
    "\n",
    "**Estimated Time:** 75-90 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction: From Individual to Collective Memory\n",
    "\n",
    "In Mini-Lecture 4, we explored the shift from **selective human memory** to **comprehensive digital memory**. Today, we'll practice this shift in our Python skills:\n",
    "\n",
    "**Previous tutorials**: Processing one person at a time\n",
    "```python\n",
    "person_age = 25\n",
    "if person_age >= 18:\n",
    "    print(\"Can vote\")\n",
    "```\n",
    "\n",
    "**This tutorial**: Processing entire populations automatically\n",
    "```python\n",
    "community_ages = [17, 25, 35, 45, 67]\n",
    "for age in community_ages:\n",
    "    if age >= 18:\n",
    "        print(f\"Age {age}: Can vote\")\n",
    "```\n",
    "\n",
    "This shift from individual to collective processing is exactly what Mini-Lecture 4 identified as the core of digital memory systems: **code that remembers and processes everyone, forever**.\n",
    "\n",
    "We'll continue working with Anelise Shrout's [Bellevue Almshouse Dataset](https://crdh.rrchnm.org/essays/v01-10-(re)-humanizing-data/) to see how historical institutional record-keeping connects to modern digital memory systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b8ba6e",
   "metadata": {},
   "source": [
    "## Prerequisites Check - Lists and Loops\n",
    "\n",
    "Before starting this tutorial, you should be comfortable with concepts from **Melanie Walsh's Lists & Loops chapters (9-10)**:\n",
    "\n",
    "‚úÖ **Creating Lists:**\n",
    "- Know how to create a list with square brackets: `names = ['Mary', 'John', 'Catherine']`\n",
    "- Understand list indexing: `names[0]` gets the first item\n",
    "- Can use `.append()` to add items to lists\n",
    "\n",
    "‚úÖ **For Loops:**\n",
    "- Write basic for loops: `for name in names:`\n",
    "- Understand indentation in loop bodies\n",
    "- Can combine loops with conditionals\n",
    "\n",
    "‚úÖ **From Previous Tutorials:**\n",
    "- Variables, data types, string methods\n",
    "- Conditional statements (`if`/`elif`/`else`)\n",
    "- Individual data processing\n",
    "\n",
    "**Self-Test:** If you can successfully work through Melanie Walsh's basic list and loop examples with the Bellevue data, you're ready for this tutorial!\n",
    "\n",
    "**Connection to Mini-Lecture 4:** These technical skills (lists = populations, loops = systematic processing) are the building blocks of the collective digital memory systems we analyzed in the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed48ec8",
   "metadata": {},
   "source": [
    "## Part 1: Individual vs. Collective Memory - A Technical Comparison\n",
    "\n",
    "Let's start by experiencing the shift from individual to collective processing that defines digital memory systems.\n",
    "\n",
    "### Traditional Individual Processing (What We've Done Before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb20c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual memory: Processing one person at a time (like village elder)\n",
    "print(\"=== Individual Memory System ===\")\n",
    "\n",
    "# One person from 1847 Bellevue Almshouse records\n",
    "person_name = \"Mary Gallagher\"\n",
    "person_age = 28\n",
    "person_disease = \"recent emigrant\"  # Remember: immigration as \"disease\"\n",
    "person_profession = \"married\"\n",
    "\n",
    "print(f\"Considering: {person_name}\")\n",
    "print(f\"Age: {person_age}, Disease: {person_disease}, Profession: {person_profession}\")\n",
    "\n",
    "# Individual decision-making with context\n",
    "if person_disease == \"recent emigrant\":\n",
    "    print(\"üí≠ Decision: Recent immigrant, needs special consideration\")\n",
    "    print(\"   Context: Fleeing famine, may need language assistance\")\n",
    "    print(\"   Human judgment: Treat with compassion despite prejudice\")\n",
    "elif person_disease == \"\":\n",
    "    print(\"üí≠ Decision: No disease recorded, assess individual needs\")\n",
    "else:\n",
    "    print(f\"üí≠ Decision: Medical condition '{person_disease}' requires care\")\n",
    "\n",
    "print(\"\\n‚è±Ô∏è Time taken: Several minutes of thoughtful consideration\")\n",
    "print(\"üß† Memory: Will partially fade, allowing for redemption and change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa36d57",
   "metadata": {},
   "source": [
    "### Digital Collective Processing (Lists + Loops = Population Control)\n",
    "\n",
    "Now let's see how lists and loops create the \"total\" digital memory system described in Mini-Lecture 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collective digital memory: Processing entire populations automatically\n",
    "print(\"=== Digital Collective Memory System ===\")\n",
    "\n",
    "# Lists = Populations (from Walsh's Bellevue dataset)\n",
    "names = ['Mary Gallagher', 'John Sanin', 'Anthony Clark', 'Margaret Farrell', \n",
    "         'Lawrence Feeney', 'Henry Joyce', 'Bridget Hart', 'Mary Green']\n",
    "\n",
    "ages = [28, 19, 60, 30, 32, 21, 20, 40]\n",
    "\n",
    "diseases = ['recent emigrant', 'recent emigrant', 'recent emigrant', 'recent emigrant',\n",
    "           'recent emigrant', '', 'recent emigrant', 'recent emigrant']\n",
    "\n",
    "professions = ['married', 'laborer', 'laborer', 'widow', \n",
    "              'laborer', '', 'spinster', 'spinster']\n",
    "\n",
    "print(f\"Processing population of {len(names)} people...\")\n",
    "print(\"\\n=== Systematic Classification in Progress ===\")\n",
    "\n",
    "# Loops = Systematic Processing (same rule applied to everyone)\n",
    "recent_emigrants = []\n",
    "for i, name in enumerate(names):\n",
    "    disease = diseases[i]\n",
    "    age = ages[i]\n",
    "    profession = professions[i]\n",
    "    \n",
    "    print(f\"Processing: {name}\")\n",
    "    \n",
    "    # Systematic rule: No context, no exceptions\n",
    "    if disease == \"recent emigrant\":\n",
    "        classification = \"HIGH RISK - Recent immigrant\"\n",
    "        recent_emigrants.append(name)\n",
    "    else:\n",
    "        classification = \"STANDARD PROCESSING\"\n",
    "    \n",
    "    print(f\"  ‚Üí Classification: {classification}\")\n",
    "    print(f\"  ‚Üí Stored permanently in digital record\")\n",
    "\n",
    "print(\"\\n=== Digital Memory Results ===\")\n",
    "print(f\"‚ö° Time taken: Milliseconds\")\n",
    "print(f\"üß† Memory: Perfect, permanent, unforgiving\")\n",
    "print(f\"üìä Recent emigrants identified: {len(recent_emigrants)} out of {len(names)}\")\n",
    "print(f\"üìã List of 'recent emigrants': {recent_emigrants}\")\n",
    "print(\"\\nüíæ All data stored forever. No forgetting. No redemption.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e304d",
   "metadata": {},
   "source": [
    "### Reflection Exercise 1\n",
    "\n",
    "**Stop and Compare:** Run both code cells above and observe the difference.\n",
    "\n",
    "1. **Speed difference**: Individual processing vs. population processing\n",
    "2. **Context difference**: Human judgment vs. systematic rules\n",
    "3. **Memory difference**: Selective forgetting vs. total digital memory\n",
    "\n",
    "**Critical Question**: The code above processes 8 people in milliseconds. How would this change if we had 8,000 people? 8 million? What are the implications for:\n",
    "- Human oversight and accountability?\n",
    "- Individual exceptions and context?\n",
    "- The possibility of redemption or change?\n",
    "\n",
    "**Connection to Mini-Lecture 4**: This is exactly the \"scale problem\" we discussed - when individual decisions become mass processing, amplifying bias from personal to societal level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd4aca4",
   "metadata": {},
   "source": [
    "## Part 2: Historical Echoes - 1840s Records to Digital Data\n",
    "\n",
    "As Anelise Shrout notes about the Bellevue Almshouse records, this data was \"produced with the express purpose of reducing people to bodies; bodies to easily quantifiable aspects.\" Let's see how the same logic operates in lists and loops.\n",
    "\n",
    "### Exercise 2a: Building Lists from Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a8f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical data from Shrout's Bellevue Almshouse dataset\n",
    "# Notice how humans become data points in lists\n",
    "\n",
    "print(\"=== From Human Stories to Data Lists ===\")\n",
    "print(\"Historical context: 1847 Irish immigrants fleeing famine\\n\")\n",
    "\n",
    "# Individual human stories\n",
    "print(\"üìú Individual Records (as they appeared in 1847):\")\n",
    "print(\"- Mary Gallagher, 28, recent emigrant, married, Child Alana 10 days\")\n",
    "print(\"- John Sanin, 19, recent emigrant, laborer, Catherine 2 mo\")\n",
    "print(\"- Anthony Clark, 60, recent emigrant, laborer, Charles Riley aged 10 days\")\n",
    "print(\"- Margaret Farrell, 30, recent emigrant, widow, [no child listed]\")\n",
    "\n",
    "print(\"\\n‚¨áÔ∏è DIGITAL TRANSFORMATION ‚¨áÔ∏è\")\n",
    "print(\"üíæ Same humans as data lists (ready for systematic processing):\\n\")\n",
    "\n",
    "# Lists reduce humans to processable data points\n",
    "names = ['Mary Gallagher', 'John Sanin', 'Anthony Clark', 'Margaret Farrell']\n",
    "ages = [28, 19, 60, 30]\n",
    "diseases = ['recent emigrant', 'recent emigrant', 'recent emigrant', 'recent emigrant']\n",
    "professions = ['married', 'laborer', 'laborer', 'widow']\n",
    "has_children = [True, True, True, False]  # Reduced to simple True/False\n",
    "\n",
    "print(f\"Names: {names}\")\n",
    "print(f\"Ages: {ages}\")\n",
    "print(f\"'Diseases': {diseases}\")\n",
    "print(f\"Professions: {professions}\")\n",
    "print(f\"Has children: {has_children}\")\n",
    "\n",
    "print(\"\\nü§î Critical observation:\")\n",
    "print(\"- Individual stories and context disappear\")\n",
    "print(\"- Complex human circumstances become simple categories\")\n",
    "print(\"- 'Recent emigrant' listed as a 'disease' - prejudice encoded in data\")\n",
    "print(\"- Ready for systematic processing without human judgment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d7ed2",
   "metadata": {},
   "source": [
    "### Exercise 2b: Systematic Counting and Classification\n",
    "\n",
    "Now let's use loops to systematically process this population data - demonstrating the power of counting that Mini-Lecture 4 discussed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systematic counting = Power to define what matters\n",
    "from collections import Counter\n",
    "\n",
    "print(\"=== The Politics of Counting (Slide 5 from Mini-Lecture 4) ===\")\n",
    "print(\"Who decides what gets counted? What categories are created?\\n\")\n",
    "\n",
    "# Count by 'disease' categories (notice the bias)\n",
    "disease_counts = Counter(diseases)\n",
    "print(\"üìä Disease Classification Counts:\")\n",
    "for disease, count in disease_counts.most_common():\n",
    "    print(f\"  '{disease}': {count} people\")\n",
    "\n",
    "print(\"\\nüö® Critical Analysis:\")\n",
    "print(\"- 'Recent emigrant' classified as disease affecting 4/4 people (100%)\")\n",
    "print(\"- This count justifies anti-immigrant policies\")\n",
    "print(\"- No category for 'fleeing famine' or 'seeking refuge'\")\n",
    "print(\"- Categories embed 1847 prejudices in 'objective' data\")\n",
    "\n",
    "# Age-based systematic processing\n",
    "print(\"\\n=== Age-Based Systematic Processing ===\")\n",
    "adults = []\n",
    "seniors = []\n",
    "youth = []\n",
    "\n",
    "for i, age in enumerate(ages):\n",
    "    name = names[i]\n",
    "    if age >= 60:\n",
    "        seniors.append(name)\n",
    "        category = \"SENIOR - Limited work capacity\"\n",
    "    elif age >= 18:\n",
    "        adults.append(name)\n",
    "        category = \"ADULT - Expected to work\"\n",
    "    else:\n",
    "        youth.append(name)\n",
    "        category = \"YOUTH - Dependent status\"\n",
    "    \n",
    "    print(f\"{name} (age {age}) ‚Üí {category}\")\n",
    "\n",
    "print(f\"\\nüìà Population Breakdown:\")\n",
    "print(f\"  Seniors: {len(seniors)} - {seniors}\")\n",
    "print(f\"  Adults: {len(adults)} - {adults}\")\n",
    "print(f\"  Youth: {len(youth)} - {youth}\")\n",
    "\n",
    "print(\"\\nüí≠ Reflection: How do these automatic categories affect:\")\n",
    "print(\"- Resource allocation decisions?\")\n",
    "print(\"- Individual dignity and agency?\")\n",
    "print(\"- Assumptions about who 'deserves' what kind of care?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be8af9",
   "metadata": {},
   "source": [
    "## Part 3: The Scale Problem - When Individual Bias Becomes Systemic\n",
    "\n",
    "Mini-Lecture 4's \"Scale Problem\" (Slide 7) showed how coding amplifies bias from individual to societal level. Let's experience this with loops processing larger populations.\n",
    "\n",
    "### Exercise 3a: Small Scale Processing (What We Just Did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d90a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small scale: 4 people - bias is visible and could be questioned\n",
    "print(\"=== Small Scale Processing (4 people) ===\")\n",
    "print(\"At this scale, bias is visible and could be questioned by humans\\n\")\n",
    "\n",
    "# Simple biased rule\n",
    "for i, name in enumerate(names):\n",
    "    disease = diseases[i]\n",
    "    age = ages[i]\n",
    "    \n",
    "    # Biased algorithm: Discriminates against immigrants\n",
    "    if disease == \"recent emigrant\":\n",
    "        priority = \"LOW PRIORITY\"\n",
    "        justification = \"Recent immigrant - limited resources allocation\"\n",
    "    else:\n",
    "        priority = \"STANDARD PRIORITY\"\n",
    "        justification = \"Established resident - normal care\"\n",
    "    \n",
    "    print(f\"{name}: {priority} - {justification}\")\n",
    "\n",
    "print(\"\\nüëÅÔ∏è At small scale:\")\n",
    "print(\"- A human could review these 4 decisions\")\n",
    "print(\"- Individual cases could be appealed\")\n",
    "print(\"- Bias is obvious and could be corrected\")\n",
    "print(\"- Someone could ask: 'Is this fair to Mary Gallagher?'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c86addc",
   "metadata": {},
   "source": [
    "### Exercise 3b: Large Scale Processing - The Same Bias Applied to Thousands\n",
    "\n",
    "Now let's see what happens when the SAME biased algorithm processes thousands of people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aefbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large scale: Simulating thousands of people with the same bias\n",
    "print(\"=== Large Scale Processing (Thousands of people) ===\")\n",
    "print(\"The SAME biased rule, now applied systematically to entire populations\\n\")\n",
    "\n",
    "# Simulate a larger population (based on historical Bellevue data patterns)\n",
    "import random\n",
    "random.seed(42)  # For reproducible results\n",
    "\n",
    "# Generate simulated population based on historical proportions\n",
    "large_population_size = 1000\n",
    "large_names = [f\"Person_{i+1}\" for i in range(large_population_size)]\n",
    "\n",
    "# Based on historical data: ~60% \"recent emigrant\", ~40% other conditions\n",
    "large_diseases = []\n",
    "for i in range(large_population_size):\n",
    "    if random.random() < 0.6:  # 60% chance\n",
    "        large_diseases.append(\"recent emigrant\")\n",
    "    else:\n",
    "        large_diseases.append(random.choice([\"\", \"sickness\", \"destitution\"]))\n",
    "\n",
    "# Apply the SAME biased algorithm at scale\n",
    "low_priority_count = 0\n",
    "standard_priority_count = 0\n",
    "recent_emigrants_affected = []\n",
    "\n",
    "print(\"‚ö° Processing 1,000 people in milliseconds...\")\n",
    "\n",
    "for i, name in enumerate(large_names):\n",
    "    disease = large_diseases[i]\n",
    "    \n",
    "    # THE SAME BIASED RULE from small scale\n",
    "    if disease == \"recent emigrant\":\n",
    "        priority = \"LOW PRIORITY\"\n",
    "        low_priority_count += 1\n",
    "        recent_emigrants_affected.append(name)\n",
    "    else:\n",
    "        priority = \"STANDARD PRIORITY\"\n",
    "        standard_priority_count += 1\n",
    "\n",
    "# Results of systematic bias\n",
    "print(\"\\nüìä SYSTEMATIC DISCRIMINATION RESULTS:\")\n",
    "print(f\"Total processed: {large_population_size} people\")\n",
    "print(f\"Low priority (discriminated): {low_priority_count} people\")\n",
    "print(f\"Standard priority: {standard_priority_count} people\")\n",
    "print(f\"Percentage discriminated against: {(low_priority_count/large_population_size)*100:.1f}%\")\n",
    "\n",
    "print(\"\\nüö® THE SCALE PROBLEM:\")\n",
    "print(f\"- The same individual bias now affects {low_priority_count} people\")\n",
    "print(\"- NO HUMAN can review 1,000 individual cases\")\n",
    "print(\"- NO APPEALS process can handle this volume\")\n",
    "print(\"- Bias becomes 'normal' because it's systematic\")\n",
    "print(f\"- {low_priority_count} people receive inferior care due to automated prejudice\")\n",
    "\n",
    "print(\"\\nüí≠ Critical Questions:\")\n",
    "print(\"- Who is accountable when an algorithm discriminates against 600+ people?\")\n",
    "print(\"- How do we identify bias in systems processing millions?\")\n",
    "print(\"- What happens to human dignity at this scale?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e03c68",
   "metadata": {},
   "source": [
    "## Part 4: Your Coding Agency - Lists and Loops as Tools for Justice\n",
    "\n",
    "Mini-Lecture 4's final slides focused on **Your Agency** (Slide 8). Let's practice using lists and loops to **audit** and **counter** systematic bias.\n",
    "\n",
    "### Exercise 4a: Auditing Collective Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Counter to audit algorithmic decisions (as mentioned in Slide 8)\n",
    "from collections import Counter\n",
    "\n",
    "print(\"=== üîç Auditing Collective Processing ===\")\n",
    "print(\"Using your new skills to analyze algorithmic bias\\n\")\n",
    "\n",
    "# Create decision records from our biased algorithm\n",
    "algorithmic_decisions = []\n",
    "for disease in large_diseases:\n",
    "    if disease == \"recent emigrant\":\n",
    "        algorithmic_decisions.append(\"DENIED\")\n",
    "    else:\n",
    "        algorithmic_decisions.append(\"APPROVED\")\n",
    "\n",
    "# Audit the decisions\n",
    "decision_counts = Counter(algorithmic_decisions)\n",
    "print(\"üìä Algorithmic Decision Audit:\")\n",
    "for decision, count in decision_counts.items():\n",
    "    percentage = (count / len(algorithmic_decisions)) * 100\n",
    "    print(f\"  {decision}: {count} people ({percentage:.1f}%)\")\n",
    "\n",
    "# Cross-reference with disease categories\n",
    "disease_counts = Counter(large_diseases)\n",
    "print(\"\\nüìã Disease Category Breakdown:\")\n",
    "for disease, count in disease_counts.most_common():\n",
    "    percentage = (count / len(large_diseases)) * 100\n",
    "    print(f\"  '{disease}': {count} people ({percentage:.1f}%)\")\n",
    "\n",
    "# Calculate bias correlation\n",
    "recent_emigrant_denials = disease_counts.get('recent emigrant', 0)\n",
    "total_denials = decision_counts.get('DENIED', 0)\n",
    "\n",
    "print(\"\\nüö® BIAS DETECTION:\")\n",
    "print(f\"People with 'recent emigrant' status: {recent_emigrant_denials}\")\n",
    "print(f\"Total denials: {total_denials}\")\n",
    "if recent_emigrant_denials == total_denials:\n",
    "    print(\"‚ö†Ô∏è PERFECT CORRELATION: 100% of denials target 'recent emigrants'\")\n",
    "    print(\"‚ö†Ô∏è This indicates systematic discrimination based on immigration status\")\n",
    "\n",
    "print(\"\\n‚úÖ Agency gained: You can now audit algorithmic bias using Counter()!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a447e1",
   "metadata": {},
   "source": [
    "### Exercise 4b: Creating Alternative Classifications\n",
    "\n",
    "Building lists that challenge dominant categories (from Slide 8: \"Build lists that challenge dominant categories\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating humanizing categories that preserve dignity\n",
    "print(\"=== üìä Creating Alternative Classifications ===\")\n",
    "print(\"Building lists that challenge discriminatory categories\\n\")\n",
    "\n",
    "# Original biased categories (what the 1847 system recorded)\n",
    "original_diseases = ['recent emigrant', 'recent emigrant', 'recent emigrant', 'recent emigrant']\n",
    "original_names = ['Mary Gallagher', 'John Sanin', 'Anthony Clark', 'Margaret Farrell']\n",
    "\n",
    "print(\"‚ùå Original Dehumanizing Categories:\")\n",
    "for i, name in enumerate(original_names):\n",
    "    print(f\"  {name}: '{original_diseases[i]}' (disease)\")\n",
    "\n",
    "print(\"\\n‚¨áÔ∏è REHUMANIZING DATA ‚¨áÔ∏è\\n\")\n",
    "\n",
    "# Alternative humanizing categories\n",
    "humanizing_categories = []\n",
    "contextual_stories = []\n",
    "resistance_narratives = []\n",
    "\n",
    "for i, name in enumerate(original_names):\n",
    "    disease = original_diseases[i]\n",
    "    \n",
    "    if disease == 'recent emigrant':\n",
    "        # Replace dehumanizing label with contextual understanding\n",
    "        humanizing_categories.append('famine survivor seeking refuge')\n",
    "        contextual_stories.append('fled life-threatening conditions in Ireland')\n",
    "        resistance_narratives.append('made dangerous journey to build new life')\n",
    "    else:\n",
    "        humanizing_categories.append('person needing care')\n",
    "        contextual_stories.append('individual circumstances require attention')\n",
    "        resistance_narratives.append('human being deserving dignity')\n",
    "\n",
    "print(\"‚úÖ Alternative Humanizing Classifications:\")\n",
    "for i, name in enumerate(original_names):\n",
    "    print(f\"  {name}:\")\n",
    "    print(f\"    Category: {humanizing_categories[i]}\")\n",
    "    print(f\"    Context: {contextual_stories[i]}\")\n",
    "    print(f\"    Narrative: {resistance_narratives[i]}\")\n",
    "    print()\n",
    "\n",
    "print(\"üìã New Category Counts:\")\n",
    "alternative_counts = Counter(humanizing_categories)\n",
    "for category, count in alternative_counts.items():\n",
    "    print(f\"  '{category}': {count} people\")\n",
    "\n",
    "print(\"\\nüéØ Impact of Alternative Categories:\")\n",
    "print(\"- Preserves human dignity and agency\")\n",
    "print(\"- Includes historical context and circumstances\")\n",
    "print(\"- Challenges systems that dehumanize vulnerable populations\")\n",
    "print(\"- Creates space for compassion rather than prejudice\")\n",
    "\n",
    "print(\"\\n‚úÖ Agency gained: You can now create counter-narratives in data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80be4b9",
   "metadata": {},
   "source": [
    "### Exercise 4c: Building More Humane Processing Systems\n",
    "\n",
    "Let's design a processing system that preserves rather than erases human complexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing humane systematic processing\n",
    "print(\"=== üõ°Ô∏è Protecting Collective Privacy and Dignity ===\")\n",
    "print(\"Processing data in ways that preserve human dignity\\n\")\n",
    "\n",
    "# Sample data for humane processing\n",
    "people_data = [\n",
    "    {'name': 'Mary Gallagher', 'age': 28, 'status': 'recent emigrant', 'children': True},\n",
    "    {'name': 'John Sanin', 'age': 19, 'status': 'recent emigrant', 'children': True},\n",
    "    {'name': 'Anthony Clark', 'age': 60, 'status': 'recent emigrant', 'children': True},\n",
    "    {'name': 'Margaret Farrell', 'age': 30, 'status': 'recent emigrant', 'children': False}\n",
    "]\n",
    "\n",
    "# Humane processing principles\n",
    "def humane_assessment(person):\n",
    "    \"\"\"Process individuals with dignity and context\"\"\"\n",
    "    \n",
    "    needs = []\n",
    "    strengths = []\n",
    "    supports = []\n",
    "    \n",
    "    # Focus on needs rather than deficits\n",
    "    if person['status'] == 'recent emigrant':\n",
    "        needs.append('language support')\n",
    "        needs.append('community integration')\n",
    "        strengths.append('courage and resilience')\n",
    "        strengths.append('cultural knowledge')\n",
    "    \n",
    "    if person['age'] > 55:\n",
    "        needs.append('age-appropriate care')\n",
    "        strengths.append('life experience and wisdom')\n",
    "    \n",
    "    if person['children']:\n",
    "        needs.append('family support services')\n",
    "        strengths.append('parenting experience')\n",
    "        supports.append('priority housing')\n",
    "    \n",
    "    # Default supports for everyone\n",
    "    supports.extend(['medical care', 'basic dignity', 'respect'])\n",
    "    \n",
    "    return {\n",
    "        'needs': needs,\n",
    "        'strengths': strengths,\n",
    "        'supports': supports,\n",
    "        'priority': 'HIGH' if person['children'] or person['age'] > 55 else 'STANDARD'\n",
    "    }\n",
    "\n",
    "# Process everyone with humane algorithm\n",
    "print(\"ü§ù Humane Processing Results:\")\n",
    "for person in people_data:\n",
    "    assessment = humane_assessment(person)\n",
    "    \n",
    "    print(f\"\\nüë§ {person['name']} (age {person['age']}):\")\n",
    "    print(f\"  Needs: {', '.join(assessment['needs'])}\")\n",
    "    print(f\"  Strengths: {', '.join(assessment['strengths'])}\")\n",
    "    print(f\"  Supports provided: {', '.join(assessment['supports'])}\")\n",
    "    print(f\"  Priority: {assessment['priority']}\")\n",
    "\n",
    "# Aggregate insights while preserving privacy\n",
    "all_needs = []\n",
    "all_strengths = []\n",
    "priority_counts = {'HIGH': 0, 'STANDARD': 0}\n",
    "\n",
    "for person in people_data:\n",
    "    assessment = humane_assessment(person)\n",
    "    all_needs.extend(assessment['needs'])\n",
    "    all_strengths.extend(assessment['strengths'])\n",
    "    priority_counts[assessment['priority']] += 1\n",
    "\n",
    "print(\"\\nüìä Anonymized Population Insights:\")\n",
    "need_counts = Counter(all_needs)\n",
    "strength_counts = Counter(all_strengths)\n",
    "\n",
    "print(\"\\nMost common needs:\")\n",
    "for need, count in need_counts.most_common(3):\n",
    "    print(f\"  {need}: {count} people\")\n",
    "\n",
    "print(\"\\nCommunity strengths identified:\")\n",
    "for strength, count in strength_counts.most_common(3):\n",
    "    print(f\"  {strength}: {count} people\")\n",
    "\n",
    "print(f\"\\nPriority distribution: {dict(priority_counts)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Humane Processing Achieved:\")\n",
    "print(\"- Focuses on needs and strengths, not deficits\")\n",
    "print(\"- Preserves individual dignity while enabling systematic care\")\n",
    "print(\"- Provides useful population insights without exposing individuals\")\n",
    "print(\"- Creates space for human complexity and context\")\n",
    "\n",
    "print(\"\\nüéØ Your Agency: You can now design systems that humanize rather than dehumanize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf8c732",
   "metadata": {},
   "source": [
    "## Part 5: Your Digital Memory - Reflection and Moving Forward\n",
    "\n",
    "As we conclude this tutorial on lists and loops, let's reflect on the connections between technical skills and social responsibility.\n",
    "\n",
    "### Final Reflection Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f960f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflection on what we've learned\n",
    "print(\"=== ü§î Your Digital Memory - What Will You Remember? ===\")\n",
    "print(\"From Mini-Lecture 4: 'What would you want a community to remember about you?'\\n\")\n",
    "\n",
    "# Technical skills gained\n",
    "technical_skills = [\n",
    "    'Creating and processing lists',\n",
    "    'Using for loops to iterate through populations',\n",
    "    'Counting and analyzing patterns with Counter()',\n",
    "    'Building new lists based on conditions',\n",
    "    'Combining multiple data sources with zip() or indexing',\n",
    "    'Systematic data processing and analysis'\n",
    "]\n",
    "\n",
    "# Critical insights gained\n",
    "critical_insights = [\n",
    "    'Lists represent populations - coding affects groups, not just individuals',\n",
    "    'Loops create systematic processing - same rule applied to everyone',\n",
    "    'Scale amplifies bias - individual prejudice becomes societal discrimination',\n",
    "    'Historical continuity - 1840s categorization logic persists in digital systems',\n",
    "    'Digital memory is unforgiving - permanent records without redemption',\n",
    "    'Agency comes from understanding and reshaping these systems'\n",
    "]\n",
    "\n",
    "# Social responsibilities\n",
    "social_responsibilities = [\n",
    "    'Audit algorithmic systems for bias and discrimination',\n",
    "    'Create alternative categories that preserve human dignity',\n",
    "    'Design processing systems that include context and nuance',\n",
    "    'Question who has power to define categories and counting rules',\n",
    "    'Advocate for humane treatment in systematic processing',\n",
    "    'Remember that behind every data point is a human story'\n",
    "]\n",
    "\n",
    "print(\"üêç Technical Skills You've Gained:\")\n",
    "for i, skill in enumerate(technical_skills, 1):\n",
    "    print(f\"  {i}. {skill}\")\n",
    "\n",
    "print(\"\\nüí≠ Critical Insights You've Developed:\")\n",
    "for i, insight in enumerate(critical_insights, 1):\n",
    "    print(f\"  {i}. {insight}\")\n",
    "\n",
    "print(\"\\nüõ°Ô∏è Social Responsibilities You Can Now Fulfill:\")\n",
    "for i, responsibility in enumerate(social_responsibilities, 1):\n",
    "    print(f\"  {i}. {responsibility}\")\n",
    "\n",
    "print(\"\\nüéØ Key Lesson from Mini-Lecture 4:\")\n",
    "print('\"Lists and loops aren\\'t just technical skills‚Äîthey\\'re tools for social justice.\"')\n",
    "\n",
    "print(\"\\nüìù Reflection Questions for Your Digital Memory:\")\n",
    "print(\"1. How will you use these technical skills to promote justice rather than perpetuate harm?\")\n",
    "print(\"2. What systems in your life process populations systematically? How might they be biased?\")\n",
    "print(\"3. How can you design digital memory systems that are more forgiving and contextual?\")\n",
    "print(\"4. What would you want a community to remember about marginalized people in data?\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps: You're now ready to analyze real datasets and build ethical systems!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b6d43e",
   "metadata": {},
   "source": [
    "## Conclusion: From Collective Digital Memory to Collective Digital Agency\n",
    "\n",
    "Congratulations! You've now experienced the shift from individual to collective processing that defines digital memory systems. More importantly, you've learned to use the same tools (lists and loops) that can perpetuate historical biases to instead audit, question, and redesign those systems.\n",
    "\n",
    "### What You've Accomplished:\n",
    "\n",
    "**Technical Mastery:**\n",
    "- Working with lists to represent populations\n",
    "- Using loops for systematic processing\n",
    "- Counting and analyzing patterns in data\n",
    "- Building filtering and classification systems\n",
    "\n",
    "**Critical Analysis:**\n",
    "- Understanding how digital memory differs from human memory\n",
    "- Recognizing the scale problem in algorithmic processing\n",
    "- Connecting historical categorization to modern systems\n",
    "- Identifying bias in systematic processing\n",
    "\n",
    "**Social Agency:**\n",
    "- Auditing collective processing for discrimination\n",
    "- Creating alternative, humanizing categories\n",
    "- Designing more ethical processing systems\n",
    "- Advocating for dignity in digital memory systems\n",
    "\n",
    "### References and Further Learning:\n",
    "\n",
    "**Primary Sources:**\n",
    "- Melanie Walsh, [*Introduction to Cultural Analytics*](https://melaniewalsh.github.io/Intro-Cultural-Analytics/), Chapters 9-10: Lists & Loops\n",
    "- Anelise Shrout, [\"(Re)Humanizing Data: Digitally Navigating the Bellevue Almshouse\"](https://crdh.rrchnm.org/essays/v01-10-(re)-humanizing-data/)\n",
    "- [Mini-Lecture 4: Collective Digital Memory](../lecture-series/mini-lecture4/index.html)\n",
    "\n",
    "**Key Insight from Shrout:**\n",
    "> \"This data was produced with the express purpose of reducing people to bodies; bodies to easily quantifiable aspects; and assigning value to those aspects which proved that the marginalized people to whom they belonged were worth less than their elite counterparts.\"\n",
    "\n",
    "**Your Challenge:**\n",
    "Use your new skills with lists and loops to build systems that enhance rather than diminish human dignity. The code remembers forever - make sure it remembers with justice and compassion.\n",
    "\n",
    "### Continue the Conversation:\n",
    "How will you apply these skills to analyze real-world systems? What collective digital memories do you want to help create?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
